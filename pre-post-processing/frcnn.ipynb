{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XrrB6w4VDXyQ"
   },
   "source": [
    "# This will run training on the training set, and evaluate against validation\n",
    "\n",
    "This is directed for stage 2 training. For stage 1 training, pipeline.config and file structures/paths will have to be corrected. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mount drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "PDTgl00O3Nrz",
    "outputId": "04d3c840-1af5-4f26-d683-03578d25fa1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# clone tensorflow models directory, install required dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 910
    },
    "colab_type": "code",
    "id": "F62fl5poskOl",
    "outputId": "d3ef4a19-5b5d-432b-dcd4-f09a6754e3f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'models'...\n",
      "remote: Enumerating objects: 75, done.\u001b[K\n",
      "remote: Counting objects: 100% (75/75), done.\u001b[K\n",
      "remote: Compressing objects: 100% (68/68), done.\u001b[K\n",
      "remote: Total 33869 (delta 24), reused 54 (delta 7), pack-reused 33794\u001b[K\n",
      "Receiving objects: 100% (33869/33869), 512.30 MiB | 15.70 MiB/s, done.\n",
      "Resolving deltas: 100% (21817/21817), done.\n",
      "Checking out files: 100% (2491/2491), done.\n",
      "Collecting pascal-voc-writer\n",
      "  Downloading https://files.pythonhosted.org/packages/9d/82/dd86999e6062fc34478f11ead7a68e6615d7e270b39624547edd1dbaba76/pascal_voc_writer-0.1.4-py2.py3-none-any.whl\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from pascal-voc-writer) (2.11.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->pascal-voc-writer) (1.1.1)\n",
      "Installing collected packages: pascal-voc-writer\n",
      "Successfully installed pascal-voc-writer-0.1.4\n",
      "Selecting previously unselected package python-bs4.\n",
      "(Reading database ... 144568 files and directories currently installed.)\n",
      "Preparing to unpack .../0-python-bs4_4.6.0-1_all.deb ...\n",
      "Unpacking python-bs4 (4.6.0-1) ...\n",
      "Selecting previously unselected package python-pkg-resources.\n",
      "Preparing to unpack .../1-python-pkg-resources_39.0.1-2_all.deb ...\n",
      "Unpacking python-pkg-resources (39.0.1-2) ...\n",
      "Selecting previously unselected package python-chardet.\n",
      "Preparing to unpack .../2-python-chardet_3.0.4-1_all.deb ...\n",
      "Unpacking python-chardet (3.0.4-1) ...\n",
      "Selecting previously unselected package python-six.\n",
      "Preparing to unpack .../3-python-six_1.11.0-2_all.deb ...\n",
      "Unpacking python-six (1.11.0-2) ...\n",
      "Selecting previously unselected package python-webencodings.\n",
      "Preparing to unpack .../4-python-webencodings_0.5-2_all.deb ...\n",
      "Unpacking python-webencodings (0.5-2) ...\n",
      "Selecting previously unselected package python-html5lib.\n",
      "Preparing to unpack .../5-python-html5lib_0.999999999-1_all.deb ...\n",
      "Unpacking python-html5lib (0.999999999-1) ...\n",
      "Selecting previously unselected package python-lxml:amd64.\n",
      "Preparing to unpack .../6-python-lxml_4.2.1-1ubuntu0.1_amd64.deb ...\n",
      "Unpacking python-lxml:amd64 (4.2.1-1ubuntu0.1) ...\n",
      "Selecting previously unselected package python-olefile.\n",
      "Preparing to unpack .../7-python-olefile_0.45.1-1_all.deb ...\n",
      "Unpacking python-olefile (0.45.1-1) ...\n",
      "Selecting previously unselected package python-pil:amd64.\n",
      "Preparing to unpack .../8-python-pil_5.1.0-1ubuntu0.2_amd64.deb ...\n",
      "Unpacking python-pil:amd64 (5.1.0-1ubuntu0.2) ...\n",
      "Setting up python-pkg-resources (39.0.1-2) ...\n",
      "Setting up python-six (1.11.0-2) ...\n",
      "Setting up python-bs4 (4.6.0-1) ...\n",
      "Setting up python-lxml:amd64 (4.2.1-1ubuntu0.1) ...\n",
      "Setting up python-olefile (0.45.1-1) ...\n",
      "Setting up python-pil:amd64 (5.1.0-1ubuntu0.2) ...\n",
      "Setting up python-webencodings (0.5-2) ...\n",
      "Setting up python-chardet (3.0.4-1) ...\n",
      "Setting up python-html5lib (0.999999999-1) ...\n",
      "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/tensorflow/models.git\n",
    "!apt-get -qq install libprotobuf-java protobuf-compiler\n",
    "!pip install pascal-voc-writer\n",
    "!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk\n",
    "!pip install -qq Cython contextlib2 pillow lxml matplotlib pycocotools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wA22wTIJs70U"
   },
   "outputs": [],
   "source": [
    "%tensorflow_version 1.x\n",
    "\n",
    "from __future__ import division, print_function, absolute_import\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "import re\n",
    "import os\n",
    "import io\n",
    "import glob\n",
    "import shutil\n",
    "import urllib.request\n",
    "import tarfile\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "import tensorflow as tf\n",
    "import cv2 \n",
    "\n",
    "from PIL import Image\n",
    "from collections import namedtuple, OrderedDict\n",
    "\n",
    "import sys\n",
    "sys.path.append('/content/models/research')\n",
    "sys.path.append('/content/models/research/slim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Cd3MJ2AmsSUP",
    "outputId": "04efd331-9210-4981-fdf0-860fa0aca270"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.2\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build and setup, set path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "tv0lCvhis_Cq",
    "outputId": "f48aea15-2ac6-4e40-fdd4-62467e4286df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running build\n",
      "running install\n",
      "running bdist_egg\n",
      "running egg_info\n",
      "creating object_detection.egg-info\n",
      "writing object_detection.egg-info/PKG-INFO\n",
      "writing dependency_links to object_detection.egg-info/dependency_links.txt\n",
      "writing requirements to object_detection.egg-info/requires.txt\n",
      "writing top-level names to object_detection.egg-info/top_level.txt\n",
      "writing manifest file 'object_detection.egg-info/SOURCES.txt'\n",
      "reading manifest file 'object_detection.egg-info/SOURCES.txt'\n",
      "writing manifest file 'object_detection.egg-info/SOURCES.txt'\n",
      "installing library code to build/bdist.linux-x86_64/egg\n",
      "running install_lib\n",
      "warning: install_lib: 'build/lib' does not exist -- no Python modules to install\n",
      "\n",
      "creating build\n",
      "creating build/bdist.linux-x86_64\n",
      "creating build/bdist.linux-x86_64/egg\n",
      "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying object_detection.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying object_detection.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying object_detection.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying object_detection.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying object_detection.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "zip_safe flag not set; analyzing archive contents...\n",
      "creating dist\n",
      "creating 'dist/object_detection-0.1-py3.6.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
      "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
      "Processing object_detection-0.1-py3.6.egg\n",
      "Copying object_detection-0.1-py3.6.egg to /usr/local/lib/python3.6/dist-packages\n",
      "Adding object-detection 0.1 to easy-install.pth file\n",
      "\n",
      "Installed /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg\n",
      "Processing dependencies for object-detection==0.1\n",
      "Searching for Cython==0.29.16\n",
      "Best match: Cython 0.29.16\n",
      "Adding Cython 0.29.16 to easy-install.pth file\n",
      "Installing cygdb script to /usr/local/bin\n",
      "Installing cython script to /usr/local/bin\n",
      "Installing cythonize script to /usr/local/bin\n",
      "\n",
      "Using /usr/local/lib/python3.6/dist-packages\n",
      "Searching for matplotlib==3.2.1\n",
      "Best match: matplotlib 3.2.1\n",
      "Adding matplotlib 3.2.1 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.6/dist-packages\n",
      "Searching for Pillow==7.0.0\n",
      "Best match: Pillow 7.0.0\n",
      "Adding Pillow 7.0.0 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.6/dist-packages\n",
      "Searching for kiwisolver==1.2.0\n",
      "Best match: kiwisolver 1.2.0\n",
      "Adding kiwisolver 1.2.0 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.6/dist-packages\n",
      "Searching for cycler==0.10.0\n",
      "Best match: cycler 0.10.0\n",
      "Adding cycler 0.10.0 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.6/dist-packages\n",
      "Searching for pyparsing==2.4.7\n",
      "Best match: pyparsing 2.4.7\n",
      "Adding pyparsing 2.4.7 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.6/dist-packages\n",
      "Searching for python-dateutil==2.8.1\n",
      "Best match: python-dateutil 2.8.1\n",
      "Adding python-dateutil 2.8.1 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.6/dist-packages\n",
      "Searching for numpy==1.18.2\n",
      "Best match: numpy 1.18.2\n",
      "Adding numpy 1.18.2 to easy-install.pth file\n",
      "Installing f2py script to /usr/local/bin\n",
      "Installing f2py3 script to /usr/local/bin\n",
      "Installing f2py3.6 script to /usr/local/bin\n",
      "\n",
      "Using /usr/local/lib/python3.6/dist-packages\n",
      "Searching for six==1.12.0\n",
      "Best match: six 1.12.0\n",
      "Adding six 1.12.0 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.6/dist-packages\n",
      "Finished processing dependencies for object-detection==0.1\n",
      "/tensorflow-1.15.2/python3.6:/env/python/:/content/models/research:/content/models/research/slim:/content/models/research/object_detection\n"
     ]
    }
   ],
   "source": [
    "!python3 /content/models/research/setup.py build\n",
    "!python3 /content/models/research/setup.py install\n",
    "\n",
    "os.environ['PYTHONPATH'] = '/tensorflow-1.15.2/python3.6:/env/python/:/content/models/research:/content/models/research/slim:/content/models/research/object_detection'\n",
    "\n",
    "print(os.environ['PYTHONPATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Vx22FhsetEPr",
    "outputId": "97049b4b-9bf1-4e7d-b9f7-143e2912facf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'cocoapi'...\n",
      "remote: Enumerating objects: 975, done.\u001b[K\n",
      "remote: Total 975 (delta 0), reused 0 (delta 0), pack-reused 975\u001b[K\n",
      "Receiving objects: 100% (975/975), 11.72 MiB | 5.68 MiB/s, done.\n",
      "Resolving deltas: 100% (576/576), done.\n",
      "python setup.py build_ext --inplace\n",
      "running build_ext\n",
      "cythoning pycocotools/_mask.pyx to pycocotools/_mask.c\n",
      "/usr/local/lib/python3.6/dist-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /content/cocoapi/PythonAPI/pycocotools/_mask.pyx\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "building 'pycocotools._mask' extension\n",
      "creating build\n",
      "creating build/common\n",
      "creating build/temp.linux-x86_64-3.6\n",
      "creating build/temp.linux-x86_64-3.6/pycocotools\n",
      "x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/numpy/core/include -I../common -I/usr/include/python3.6m -c ../common/maskApi.c -o build/temp.linux-x86_64-3.6/../common/maskApi.o -Wno-cpp -Wno-unused-function -std=c99\n",
      "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleDecode\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K../common/maskApi.c:46:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
      "       \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K( k=0; k<R[i].cnts[j]; k++ ) *(M++)=v; v=!v; }}\n",
      "       \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:46:49:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n",
      "       for( k=0; k<R[i].cnts[j]; k++ ) *(M++)=v; \u001b[01;36m\u001b[Kv\u001b[m\u001b[K=!v; }}\n",
      "                                                 \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleFrPoly\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K../common/maskApi.c:166:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
      "   \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K(j=0; j<k; j++) x[j]=(int)(scale*xy[j*2+0]+.5); x[k]=x[0];\n",
      "   \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:166:54:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n",
      "   for(j=0; j<k; j++) x[j]=(int)(scale*xy[j*2+0]+.5); \u001b[01;36m\u001b[Kx\u001b[m\u001b[K[k]=x[0];\n",
      "                                                      \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:167:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
      "   \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K(j=0; j<k; j++) y[j]=(int)(scale*xy[j*2+1]+.5); y[k]=y[0];\n",
      "   \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:167:54:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n",
      "   for(j=0; j<k; j++) y[j]=(int)(scale*xy[j*2+1]+.5); \u001b[01;36m\u001b[Ky\u001b[m\u001b[K[k]=y[0];\n",
      "                                                      \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleToString\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K../common/maskApi.c:212:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
      "       \u001b[01;35m\u001b[Kif\u001b[m\u001b[K(more) c |= 0x20; c+=48; s[p++]=c;\n",
      "       \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:212:27:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’\n",
      "       if(more) c |= 0x20; \u001b[01;36m\u001b[Kc\u001b[m\u001b[K+=48; s[p++]=c;\n",
      "                           \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleFrString\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K../common/maskApi.c:220:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kwhile\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
      "   \u001b[01;35m\u001b[Kwhile\u001b[m\u001b[K( s[m] ) m++; cnts=malloc(sizeof(uint)*m); m=0;\n",
      "   \u001b[01;35m\u001b[K^~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:220:22:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kwhile\u001b[m\u001b[K’\n",
      "   while( s[m] ) m++; \u001b[01;36m\u001b[Kcnts\u001b[m\u001b[K=malloc(sizeof(uint)*m); m=0;\n",
      "                      \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:228:5:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
      "     \u001b[01;35m\u001b[Kif\u001b[m\u001b[K(m>2) x+=(long) cnts[m-2]; cnts[m++]=(uint) x;\n",
      "     \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:228:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’\n",
      "     if(m>2) x+=(long) cnts[m-2]; \u001b[01;36m\u001b[Kcnts\u001b[m\u001b[K[m++]=(uint) x;\n",
      "                                  \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleToBbox\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K../common/maskApi.c:141:31:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kxp\u001b[m\u001b[K’ may be used uninitialized in this function [\u001b[01;35m\u001b[K-Wmaybe-uninitialized\u001b[m\u001b[K]\n",
      "       if(j%2==0) xp=x; else if\u001b[01;35m\u001b[K(\u001b[m\u001b[Kxp<x) { ys=0; ye=h-1; }\n",
      "                               \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
      "x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/numpy/core/include -I../common -I/usr/include/python3.6m -c pycocotools/_mask.c -o build/temp.linux-x86_64-3.6/pycocotools/_mask.o -Wno-cpp -Wno-unused-function -std=c99\n",
      "creating build/lib.linux-x86_64-3.6\n",
      "creating build/lib.linux-x86_64-3.6/pycocotools\n",
      "x86_64-linux-gnu-gcc -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/../common/maskApi.o build/temp.linux-x86_64-3.6/pycocotools/_mask.o -o build/lib.linux-x86_64-3.6/pycocotools/_mask.cpython-36m-x86_64-linux-gnu.so\n",
      "copying build/lib.linux-x86_64-3.6/pycocotools/_mask.cpython-36m-x86_64-linux-gnu.so -> pycocotools\n",
      "rm -rf build\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/cocodataset/cocoapi.git\n",
    "!cd cocoapi/PythonAPI; make; cp -r pycocotools /content/models/research/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build .proto files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rsiQHhOxtFZr"
   },
   "outputs": [],
   "source": [
    "!cd /content/models/research;protoc object_detection/protos/*.proto --python_out=."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check object_detection installed correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 806
    },
    "colab_type": "code",
    "id": "s9Bo8sQytHVv",
    "outputId": "38954dfe-787e-465b-ac69-1cbf0c8e5555"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "Running tests under Python 3.6.9: /usr/bin/python3\n",
      "[ RUN      ] ModelBuilderTest.test_create_experimental_model\n",
      "[       OK ] ModelBuilderTest.test_create_experimental_model\n",
      "[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_model_from_config_with_example_miner\n",
      "[       OK ] ModelBuilderTest.test_create_faster_rcnn_model_from_config_with_example_miner\n",
      "[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
      "[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
      "[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
      "[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
      "[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
      "[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
      "[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
      "[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
      "[ RUN      ] ModelBuilderTest.test_create_rfcn_model_from_config\n",
      "[       OK ] ModelBuilderTest.test_create_rfcn_model_from_config\n",
      "[ RUN      ] ModelBuilderTest.test_create_ssd_fpn_model_from_config\n",
      "[       OK ] ModelBuilderTest.test_create_ssd_fpn_model_from_config\n",
      "[ RUN      ] ModelBuilderTest.test_create_ssd_models_from_config\n",
      "[       OK ] ModelBuilderTest.test_create_ssd_models_from_config\n",
      "[ RUN      ] ModelBuilderTest.test_invalid_faster_rcnn_batchnorm_update\n",
      "[       OK ] ModelBuilderTest.test_invalid_faster_rcnn_batchnorm_update\n",
      "[ RUN      ] ModelBuilderTest.test_invalid_first_stage_nms_iou_threshold\n",
      "[       OK ] ModelBuilderTest.test_invalid_first_stage_nms_iou_threshold\n",
      "[ RUN      ] ModelBuilderTest.test_invalid_model_config_proto\n",
      "[       OK ] ModelBuilderTest.test_invalid_model_config_proto\n",
      "[ RUN      ] ModelBuilderTest.test_invalid_second_stage_batch_size\n",
      "[       OK ] ModelBuilderTest.test_invalid_second_stage_batch_size\n",
      "[ RUN      ] ModelBuilderTest.test_session\n",
      "[  SKIPPED ] ModelBuilderTest.test_session\n",
      "[ RUN      ] ModelBuilderTest.test_unknown_faster_rcnn_feature_extractor\n",
      "[       OK ] ModelBuilderTest.test_unknown_faster_rcnn_feature_extractor\n",
      "[ RUN      ] ModelBuilderTest.test_unknown_meta_architecture\n",
      "[       OK ] ModelBuilderTest.test_unknown_meta_architecture\n",
      "[ RUN      ] ModelBuilderTest.test_unknown_ssd_feature_extractor\n",
      "[       OK ] ModelBuilderTest.test_unknown_ssd_feature_extractor\n",
      "----------------------------------------------------------------------\n",
      "Ran 17 tests in 0.160s\n",
      "\n",
      "OK (skipped=1)\n"
     ]
    }
   ],
   "source": [
    "!python3 /content/models/research/object_detection/builders/model_builder_test.py\n",
    "\n",
    "#output at the end should be OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "CE37MM3Jtp8Q",
    "outputId": "d7e233d5-5729-4eb4-c2e1-608e878c836b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16508\n",
      "2004\n",
      "12500\n",
      "2004\n"
     ]
    }
   ],
   "source": [
    "print(len(os.listdir('/content/drive/My Drive/all_img_final')))\n",
    "#print(len(files))\n",
    "print(len(os.listdir('/content/drive/My Drive/xmls/testxml')))\n",
    "print(len(os.listdir('/content/drive/My Drive/xmls/trainxml')))\n",
    "print(len(os.listdir('/content/drive/My Drive/xmls/valxml')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# to create tfrecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Q4H-3P-4tZZe",
    "outputId": "bfb0bfa1-4be4-47e4-b5ec-da38bf9b5a92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "600\n",
      "601\n",
      "602\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n",
      "607\n",
      "608\n",
      "609\n",
      "610\n",
      "611\n",
      "612\n",
      "613\n",
      "614\n",
      "615\n",
      "616\n",
      "617\n",
      "618\n",
      "619\n",
      "620\n",
      "621\n",
      "622\n",
      "623\n",
      "624\n",
      "625\n",
      "626\n",
      "627\n",
      "628\n",
      "629\n",
      "630\n",
      "631\n",
      "632\n",
      "633\n",
      "634\n",
      "635\n",
      "636\n",
      "637\n",
      "638\n",
      "639\n",
      "640\n",
      "641\n",
      "642\n",
      "643\n",
      "644\n",
      "645\n",
      "646\n",
      "647\n",
      "648\n",
      "649\n",
      "650\n",
      "651\n",
      "652\n",
      "653\n",
      "654\n",
      "655\n",
      "656\n",
      "657\n",
      "658\n",
      "659\n",
      "660\n",
      "661\n",
      "662\n",
      "663\n",
      "664\n",
      "665\n",
      "666\n",
      "667\n",
      "668\n",
      "669\n",
      "670\n",
      "671\n",
      "672\n",
      "673\n",
      "674\n",
      "675\n",
      "676\n",
      "677\n",
      "678\n",
      "679\n",
      "680\n",
      "681\n",
      "682\n",
      "683\n",
      "684\n",
      "685\n",
      "686\n",
      "687\n",
      "688\n",
      "689\n",
      "690\n",
      "691\n",
      "692\n",
      "693\n",
      "694\n",
      "695\n",
      "696\n",
      "697\n",
      "698\n",
      "699\n",
      "700\n",
      "701\n",
      "702\n",
      "703\n",
      "704\n",
      "705\n",
      "706\n",
      "707\n",
      "708\n",
      "709\n",
      "710\n",
      "711\n",
      "712\n",
      "713\n",
      "714\n",
      "715\n",
      "716\n",
      "717\n",
      "718\n",
      "719\n",
      "720\n",
      "721\n",
      "722\n",
      "723\n",
      "724\n",
      "725\n",
      "726\n",
      "727\n",
      "728\n",
      "729\n",
      "730\n",
      "731\n",
      "732\n",
      "733\n",
      "734\n",
      "735\n",
      "736\n",
      "737\n",
      "738\n",
      "739\n",
      "740\n",
      "741\n",
      "742\n",
      "743\n",
      "744\n",
      "745\n",
      "746\n",
      "747\n",
      "748\n",
      "749\n",
      "750\n",
      "751\n",
      "752\n",
      "753\n",
      "754\n",
      "755\n",
      "756\n",
      "757\n",
      "758\n",
      "759\n",
      "760\n",
      "761\n",
      "762\n",
      "763\n",
      "764\n",
      "765\n",
      "766\n",
      "767\n",
      "768\n",
      "769\n",
      "770\n",
      "771\n",
      "772\n",
      "773\n",
      "774\n",
      "775\n",
      "776\n",
      "777\n",
      "778\n",
      "779\n",
      "780\n",
      "781\n",
      "782\n",
      "783\n",
      "784\n",
      "785\n",
      "786\n",
      "787\n",
      "788\n",
      "789\n",
      "790\n",
      "791\n",
      "792\n",
      "793\n",
      "794\n",
      "795\n",
      "796\n",
      "797\n",
      "798\n",
      "799\n",
      "800\n",
      "801\n",
      "802\n",
      "803\n",
      "804\n",
      "805\n",
      "806\n",
      "807\n",
      "808\n",
      "809\n",
      "810\n",
      "811\n",
      "812\n",
      "813\n",
      "814\n",
      "815\n",
      "816\n",
      "817\n",
      "818\n",
      "819\n",
      "820\n",
      "821\n",
      "822\n",
      "823\n",
      "824\n",
      "825\n",
      "826\n",
      "827\n",
      "828\n",
      "829\n",
      "830\n",
      "831\n",
      "832\n",
      "833\n",
      "834\n",
      "835\n",
      "836\n",
      "837\n",
      "838\n",
      "839\n",
      "840\n",
      "841\n",
      "842\n",
      "843\n",
      "844\n",
      "845\n",
      "846\n",
      "847\n",
      "848\n",
      "849\n",
      "850\n",
      "851\n",
      "852\n",
      "853\n",
      "854\n",
      "855\n",
      "856\n",
      "857\n",
      "858\n",
      "859\n",
      "860\n",
      "861\n",
      "862\n",
      "863\n",
      "864\n",
      "865\n",
      "866\n",
      "867\n",
      "868\n",
      "869\n",
      "870\n",
      "871\n",
      "872\n",
      "873\n",
      "874\n",
      "875\n",
      "876\n",
      "877\n",
      "878\n",
      "879\n",
      "880\n",
      "881\n",
      "882\n",
      "883\n",
      "884\n",
      "885\n",
      "886\n",
      "887\n",
      "888\n",
      "889\n",
      "890\n",
      "891\n",
      "892\n",
      "893\n",
      "894\n",
      "895\n",
      "896\n",
      "897\n",
      "898\n",
      "899\n",
      "900\n",
      "901\n",
      "902\n",
      "903\n",
      "904\n",
      "905\n",
      "906\n",
      "907\n",
      "908\n",
      "909\n",
      "910\n",
      "911\n",
      "912\n",
      "913\n",
      "914\n",
      "915\n",
      "916\n",
      "917\n",
      "918\n",
      "919\n",
      "920\n",
      "921\n",
      "922\n",
      "923\n",
      "924\n",
      "925\n",
      "926\n",
      "927\n",
      "928\n",
      "929\n",
      "930\n",
      "931\n",
      "932\n",
      "933\n",
      "934\n",
      "935\n",
      "936\n",
      "937\n",
      "938\n",
      "939\n",
      "940\n",
      "941\n",
      "942\n",
      "943\n",
      "944\n",
      "945\n",
      "946\n",
      "947\n",
      "948\n",
      "949\n",
      "950\n",
      "951\n",
      "952\n",
      "953\n",
      "954\n",
      "955\n",
      "956\n",
      "957\n",
      "958\n",
      "959\n",
      "960\n",
      "961\n",
      "962\n",
      "963\n",
      "964\n",
      "965\n",
      "966\n",
      "967\n",
      "968\n",
      "969\n",
      "970\n",
      "971\n",
      "972\n",
      "973\n",
      "974\n",
      "975\n",
      "976\n",
      "977\n",
      "978\n",
      "979\n",
      "980\n",
      "981\n",
      "982\n",
      "983\n",
      "984\n",
      "985\n",
      "986\n",
      "987\n",
      "988\n",
      "989\n",
      "990\n",
      "991\n",
      "992\n",
      "993\n",
      "994\n",
      "995\n",
      "996\n",
      "997\n",
      "998\n",
      "999\n",
      "1000\n",
      "1001\n",
      "1002\n",
      "1003\n",
      "1004\n",
      "1005\n",
      "1006\n",
      "1007\n",
      "1008\n",
      "1009\n",
      "1010\n",
      "1011\n",
      "1012\n",
      "1013\n",
      "1014\n",
      "1015\n",
      "1016\n",
      "1017\n",
      "1018\n",
      "1019\n",
      "1020\n",
      "1021\n",
      "1022\n",
      "1023\n",
      "1024\n",
      "1025\n",
      "1026\n",
      "1027\n",
      "1028\n",
      "1029\n",
      "1030\n",
      "1031\n",
      "1032\n",
      "1033\n",
      "1034\n",
      "1035\n",
      "1036\n",
      "1037\n",
      "1038\n",
      "1039\n",
      "1040\n",
      "1041\n",
      "1042\n",
      "1043\n",
      "1044\n",
      "1045\n",
      "1046\n",
      "1047\n",
      "1048\n",
      "1049\n",
      "1050\n",
      "1051\n",
      "1052\n",
      "1053\n",
      "1054\n",
      "1055\n",
      "1056\n",
      "1057\n",
      "1058\n",
      "1059\n",
      "1060\n",
      "1061\n",
      "1062\n",
      "1063\n",
      "1064\n",
      "1065\n",
      "1066\n",
      "1067\n",
      "1068\n",
      "1069\n",
      "1070\n",
      "1071\n",
      "1072\n",
      "1073\n",
      "1074\n",
      "1075\n",
      "1076\n",
      "1077\n",
      "1078\n",
      "1079\n",
      "1080\n",
      "1081\n",
      "1082\n",
      "1083\n",
      "1084\n",
      "1085\n",
      "1086\n",
      "1087\n",
      "1088\n",
      "1089\n",
      "1090\n",
      "1091\n",
      "1092\n",
      "1093\n",
      "1094\n",
      "1095\n",
      "1096\n",
      "1097\n",
      "1098\n",
      "1099\n",
      "1100\n",
      "1101\n",
      "1102\n",
      "1103\n",
      "1104\n",
      "1105\n",
      "1106\n",
      "1107\n",
      "1108\n",
      "1109\n",
      "1110\n",
      "1111\n",
      "1112\n",
      "1113\n",
      "1114\n",
      "1115\n",
      "1116\n",
      "1117\n",
      "1118\n",
      "1119\n",
      "1120\n",
      "1121\n",
      "1122\n",
      "1123\n",
      "1124\n",
      "1125\n",
      "1126\n",
      "1127\n",
      "1128\n",
      "1129\n",
      "1130\n",
      "1131\n",
      "1132\n",
      "1133\n",
      "1134\n",
      "1135\n",
      "1136\n",
      "1137\n",
      "1138\n",
      "1139\n",
      "1140\n",
      "1141\n",
      "1142\n",
      "1143\n",
      "1144\n",
      "1145\n",
      "1146\n",
      "1147\n",
      "1148\n",
      "1149\n",
      "1150\n",
      "1151\n",
      "1152\n",
      "1153\n",
      "1154\n",
      "1155\n",
      "1156\n",
      "1157\n",
      "1158\n",
      "1159\n",
      "1160\n",
      "1161\n",
      "1162\n",
      "1163\n",
      "1164\n",
      "1165\n",
      "1166\n",
      "1167\n",
      "1168\n",
      "1169\n",
      "1170\n",
      "1171\n",
      "1172\n",
      "1173\n",
      "1174\n",
      "1175\n",
      "1176\n",
      "1177\n",
      "1178\n",
      "1179\n",
      "1180\n",
      "1181\n",
      "1182\n",
      "1183\n",
      "1184\n",
      "1185\n",
      "1186\n",
      "1187\n",
      "1188\n",
      "1189\n",
      "1190\n",
      "1191\n",
      "1192\n",
      "1193\n",
      "1194\n",
      "1195\n",
      "1196\n",
      "1197\n",
      "1198\n",
      "1199\n",
      "1200\n",
      "1201\n",
      "1202\n",
      "1203\n",
      "1204\n",
      "1205\n",
      "1206\n",
      "1207\n",
      "1208\n",
      "1209\n",
      "1210\n",
      "1211\n",
      "1212\n",
      "1213\n",
      "1214\n",
      "1215\n",
      "1216\n",
      "1217\n",
      "1218\n",
      "1219\n",
      "1220\n",
      "1221\n",
      "1222\n",
      "1223\n",
      "1224\n",
      "1225\n",
      "1226\n",
      "1227\n",
      "1228\n",
      "1229\n",
      "1230\n",
      "1231\n",
      "1232\n",
      "1233\n",
      "1234\n",
      "1235\n",
      "1236\n",
      "1237\n",
      "1238\n",
      "1239\n",
      "1240\n",
      "1241\n",
      "1242\n",
      "1243\n",
      "1244\n",
      "1245\n",
      "1246\n",
      "1247\n",
      "1248\n",
      "1249\n",
      "1250\n",
      "1251\n",
      "1252\n",
      "1253\n",
      "1254\n",
      "1255\n",
      "1256\n",
      "1257\n",
      "1258\n",
      "1259\n",
      "1260\n",
      "1261\n",
      "1262\n",
      "1263\n",
      "1264\n",
      "1265\n",
      "1266\n",
      "1267\n",
      "1268\n",
      "1269\n",
      "1270\n",
      "1271\n",
      "1272\n",
      "1273\n",
      "1274\n",
      "1275\n",
      "1276\n",
      "1277\n",
      "1278\n",
      "1279\n",
      "1280\n",
      "1281\n",
      "1282\n",
      "1283\n",
      "1284\n",
      "1285\n",
      "1286\n",
      "1287\n",
      "1288\n",
      "1289\n",
      "1290\n",
      "1291\n",
      "1292\n",
      "1293\n",
      "1294\n",
      "1295\n",
      "1296\n",
      "1297\n",
      "1298\n",
      "1299\n",
      "1300\n",
      "1301\n",
      "1302\n",
      "1303\n",
      "1304\n",
      "1305\n",
      "1306\n",
      "1307\n",
      "1308\n",
      "1309\n",
      "1310\n",
      "1311\n",
      "1312\n",
      "1313\n",
      "1314\n",
      "1315\n",
      "1316\n",
      "1317\n",
      "1318\n",
      "1319\n",
      "1320\n",
      "1321\n",
      "1322\n",
      "1323\n",
      "1324\n",
      "1325\n",
      "1326\n",
      "1327\n",
      "1328\n",
      "1329\n",
      "1330\n",
      "1331\n",
      "1332\n",
      "1333\n",
      "1334\n",
      "1335\n",
      "1336\n",
      "1337\n",
      "1338\n",
      "1339\n",
      "1340\n",
      "1341\n",
      "1342\n",
      "1343\n",
      "1344\n",
      "1345\n",
      "1346\n",
      "1347\n",
      "1348\n",
      "1349\n",
      "1350\n",
      "1351\n",
      "1352\n",
      "1353\n",
      "1354\n",
      "1355\n",
      "1356\n",
      "1357\n",
      "1358\n",
      "1359\n",
      "1360\n",
      "1361\n",
      "1362\n",
      "1363\n",
      "1364\n",
      "1365\n",
      "1366\n",
      "1367\n",
      "1368\n",
      "1369\n",
      "1370\n",
      "1371\n",
      "1372\n",
      "1373\n",
      "1374\n",
      "1375\n",
      "1376\n",
      "1377\n",
      "1378\n",
      "1379\n",
      "1380\n",
      "1381\n",
      "1382\n",
      "1383\n",
      "1384\n",
      "1385\n",
      "1386\n",
      "1387\n",
      "1388\n",
      "1389\n",
      "1390\n",
      "1391\n",
      "1392\n",
      "1393\n",
      "1394\n",
      "1395\n",
      "1396\n",
      "1397\n",
      "1398\n",
      "1399\n",
      "1400\n",
      "1401\n",
      "1402\n",
      "1403\n",
      "1404\n",
      "1405\n",
      "1406\n",
      "1407\n",
      "1408\n",
      "1409\n",
      "1410\n",
      "1411\n",
      "1412\n",
      "1413\n",
      "1414\n",
      "1415\n",
      "1416\n",
      "1417\n",
      "1418\n",
      "1419\n",
      "1420\n",
      "1421\n",
      "1422\n",
      "1423\n",
      "1424\n",
      "1425\n",
      "1426\n",
      "1427\n",
      "1428\n",
      "1429\n",
      "1430\n",
      "1431\n",
      "1432\n",
      "1433\n",
      "1434\n",
      "1435\n",
      "1436\n",
      "1437\n",
      "1438\n",
      "1439\n",
      "1440\n",
      "1441\n",
      "1442\n",
      "1443\n",
      "1444\n",
      "1445\n",
      "1446\n",
      "1447\n",
      "1448\n",
      "1449\n",
      "1450\n",
      "1451\n",
      "1452\n",
      "1453\n",
      "1454\n",
      "1455\n",
      "1456\n",
      "1457\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-c9de772660e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0midx\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mtf_example\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_tf_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf_example\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-c9de772660e0>\u001b[0m in \u001b[0;36mcreate_tf_example\u001b[0;34m(group, path)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_tf_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfid\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mencoded_jpg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mencoded_jpg_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_jpg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_jpg_io\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/lib/io/file_io.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    126\u001b[0m       \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     return self._prepare_value(\n\u001b[0;32m--> 128\u001b[0;31m         pywrap_tensorflow.ReadFromStream(self._read_buf, length))\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m   @deprecation.deprecated_args(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''from object_detection.utils import dataset_util\n",
    "#run once\n",
    "\n",
    "#change this to the base directory where your data/ is \n",
    "data_base_url = '/content/drive/My Drive'\n",
    "\n",
    "#location of images\n",
    "image_dir = os.path.join(data_base_url,'all_img_final')\n",
    "\n",
    "def class_text_to_int(row_label):\n",
    "    if row_label == 'glioma':\n",
    "        return 1\n",
    "    elif row_label == 'meningioma':\n",
    "        return 2\n",
    "    elif row_label == 'pituitary tumour':\n",
    "        return 3\n",
    "    else:\n",
    "        None\n",
    "\n",
    "def split(df, group):\n",
    "    data = namedtuple('data', ['filename', 'object'])\n",
    "    gb = df.groupby(group)\n",
    "    return [data(filename, gb.get_group(x)) for filename, x in zip(gb.groups.keys(), gb.groups)]\n",
    "\n",
    "def create_tf_example(group, path):\n",
    "    with tf.io.gfile.GFile(os.path.join(path, '{}'.format(group.filename)), 'rb') as fid:\n",
    "        encoded_jpg = fid.read()\n",
    "    encoded_jpg_io = io.BytesIO(encoded_jpg)\n",
    "    image = Image.open(encoded_jpg_io)\n",
    "    width, height = image.size\n",
    "    filename = group.filename.encode('utf8')\n",
    "    image_format = b'jpg'\n",
    "    xmins = []\n",
    "    xmaxs = []\n",
    "    ymins = []\n",
    "    ymaxs = []\n",
    "    classes_text = []\n",
    "    classes = []\n",
    "\n",
    "    for index, row in group.object.iterrows():\n",
    "\t\t    xmins.append(row['xmin'] / width)\n",
    "\t\t    xmaxs.append(row['xmax'] / width)\n",
    "\t\t    ymins.append(row['ymin'] / height)\n",
    "\t\t    ymaxs.append(row['ymax'] / height)\n",
    "\t\t    classes_text.append(row['class'].encode('utf8'))\n",
    "\t\t    classes.append(class_text_to_int(row['class']))\n",
    "\n",
    "    tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
    "\t\t    'image/height': dataset_util.int64_feature(height),\n",
    "\t\t    'image/width': dataset_util.int64_feature(width),\n",
    "\t\t    'image/filename': dataset_util.bytes_feature(filename),\n",
    "\t\t    'image/source_id': dataset_util.bytes_feature(filename),\n",
    "\t\t    'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n",
    "\t\t    'image/format': dataset_util.bytes_feature(image_format),\n",
    "\t\t    'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
    "\t\t    'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
    "\t\t    'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
    "\t\t    'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
    "\t\t    'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
    "\t\t    'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
    "\t\t    }))\n",
    "\n",
    "    return tf_example\n",
    "\n",
    "#creates tfrecord for csvs\n",
    "for csv in ['xmls/trainxml']:\n",
    "    idx = 1\n",
    "    writer = tf.io.TFRecordWriter(os.path.join(data_base_url, csv)+'.record')\n",
    "    path = os.path.join(image_dir)\n",
    "    examples = pd.read_csv(os.path.join(data_base_url,csv) + '.csv')\n",
    "    grouped = split(examples, 'filename')\n",
    "    for group in grouped:\n",
    "        print(idx)\n",
    "        idx += 1\n",
    "        tf_example = create_tf_example(group, path)\n",
    "        writer.write(tf_example.SerializeToString())\n",
    "    \n",
    "    writer.close()\n",
    "    output_path = os.path.join(data_base_url,csv) + '.record'\n",
    "    print('Successfully created the TFRecords: {}'.format(os.path.join(data_base_url,csv) + '.record'))'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# select model and download\n",
    "\n",
    "if resuming training, do not need to run the next 3 cells.\n",
    "if fine tuning pre-trained model, do not need to run the next  cells. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QiwEpwFp0Mwl"
   },
   "outputs": [],
   "source": [
    "# Some models to train on\n",
    "MODELS_CONFIG = {\n",
    "    'faster_rcnn_inception_v2': {\n",
    "        'model_name': 'faster_rcnn_inception_v2_coco_2018_01_28',\n",
    "    },\n",
    "    'faster_rcnn_resnet50': {\n",
    "        'model_name': 'faster_rcnn_resnet50_coco_2018_01_28',\n",
    "    },\n",
    "    'faster_rcnn_resnet101': {\n",
    "        'model_name': 'faster_rcnn_resnet101_coco_2018_01_28',\n",
    "    },\n",
    "    'faster_rcnn_inception_resnet_v2': {\n",
    "        'model_name': 'faster_rcnn_inception_resnet_v2_atrous_coco_2018_01_28',\n",
    "    },\n",
    "}\n",
    "\n",
    "# Select a model from `MODELS_CONFIG`.\n",
    "# I chose ssd_mobilenet_v2 for this project, you could choose any\n",
    "selected_model = 'faster_rcnn_inception_resnet_v2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "Yr5sUxMV0VbF",
    "outputId": "13c091b3-2ef6-4481-ca3f-13a8d74bc584"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# Name of the object detection model to use.\\nMODEL = MODELS_CONFIG[selected_model]['model_name']\\n\\n#selecting the model\\nMODEL_FILE = MODEL + '.tar.gz'\\n\\n#creating the downlaod link for the model selected\\nDOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\\n\\n#checks if the model has already been downloaded, download it otherwise\\nif not (os.path.exists(MODEL_FILE)):\\n    urllib.request.urlretrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\\n\\n#unzipping the model and extracting its content\\ntar = tarfile.open(MODEL_FILE)\\ntar.extractall()\\ntar.close()\\n\\n# creating an output file to save the model while training\\nos.remove(MODEL_FILE)\\nif (os.path.exists(DEST_DIR)):\\n    shutil.rmtree(DEST_DIR)\\nshutil.move(MODEL, DEST_DIR)\""
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the distination folder where the model will be saved\n",
    "#change this if you have a different working dir\n",
    "DEST_DIR = '/content/drive/My Drive/model_frcnn_inception_resnet_v2_final'\n",
    "\n",
    "# Name of the object detection model to use.\n",
    "MODEL = MODELS_CONFIG[selected_model]['model_name']\n",
    "\n",
    "#selecting the model\n",
    "MODEL_FILE = MODEL + '.tar.gz'\n",
    "\n",
    "#creating the downlaod link for the model selected\n",
    "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
    "\n",
    "#checks if the model has already been downloaded, download it otherwise\n",
    "if not (os.path.exists(MODEL_FILE)):\n",
    "    urllib.request.urlretrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
    "\n",
    "#unzipping the model and extracting its content\n",
    "tar = tarfile.open(MODEL_FILE)\n",
    "tar.extractall()\n",
    "tar.close()\n",
    "\n",
    "# creating an output file to save the model while training\n",
    "os.remove(MODEL_FILE)\n",
    "if (os.path.exists(DEST_DIR)):\n",
    "    shutil.rmtree(DEST_DIR)\n",
    "shutil.move(MODEL, DEST_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wmP2BbWj0-M-"
   },
   "outputs": [],
   "source": [
    "# if above cell was not run, manually set DEST_DIR\n",
    "CONFIG_PATH = DEST_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "bMmjkVhI1DGk",
    "outputId": "b3a9684f-3e3a-41ff-dd4d-3260cbbd628e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "model {\n",
      "  faster_rcnn {\n",
      "    num_classes: 3\n",
      "    image_resizer {\n",
      "      keep_aspect_ratio_resizer {\n",
      "        min_dimension: 600\n",
      "        max_dimension: 1024\n",
      "      }\n",
      "    }\n",
      "    feature_extractor {\n",
      "      type: 'faster_rcnn_inception_resnet_v2'\n",
      "      first_stage_features_stride: 8\n",
      "    }\n",
      "    first_stage_anchor_generator {\n",
      "      grid_anchor_generator {\n",
      "        scales: [0.25, 0.5, 1.0, 2.0]\n",
      "        aspect_ratios: [0.5, 1.0, 2.0]\n",
      "        height_stride: 8\n",
      "        width_stride: 8\n",
      "      }\n",
      "    }\n",
      "    first_stage_atrous_rate: 2\n",
      "    first_stage_box_predictor_conv_hyperparams {\n",
      "      op: CONV\n",
      "      regularizer {\n",
      "        l2_regularizer {\n",
      "          weight: 0.0\n",
      "        }\n",
      "      }\n",
      "      initializer {\n",
      "        truncated_normal_initializer {\n",
      "          stddev: 0.01\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    first_stage_nms_score_threshold: 0.0\n",
      "    first_stage_nms_iou_threshold: 0.7\n",
      "    first_stage_max_proposals: 300\n",
      "    first_stage_localization_loss_weight: 2.0\n",
      "    first_stage_objectness_loss_weight: 1.0\n",
      "    initial_crop_size: 17\n",
      "    maxpool_kernel_size: 1\n",
      "    maxpool_stride: 1\n",
      "    second_stage_box_predictor {\n",
      "      mask_rcnn_box_predictor {\n",
      "        use_dropout: false\n",
      "        dropout_keep_probability: 1.0\n",
      "        fc_hyperparams {\n",
      "          op: FC\n",
      "          regularizer {\n",
      "            l2_regularizer {\n",
      "              weight: 0.0\n",
      "            }\n",
      "          }\n",
      "          initializer {\n",
      "            variance_scaling_initializer {\n",
      "              factor: 1.0\n",
      "              uniform: true\n",
      "              mode: FAN_AVG\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    second_stage_post_processing {\n",
      "      batch_non_max_suppression {\n",
      "        score_threshold: 0.0\n",
      "        iou_threshold: 0.6\n",
      "        max_detections_per_class: 100\n",
      "        max_total_detections: 300\n",
      "      }\n",
      "      score_converter: SOFTMAX\n",
      "    }\n",
      "    second_stage_localization_loss_weight: 2.0\n",
      "    second_stage_classification_loss_weight: 1.0\n",
      "  }\n",
      "}\n",
      "\n",
      "train_config: {\n",
      "  batch_size: 1\n",
      "  optimizer {\n",
      "    momentum_optimizer: {\n",
      "      learning_rate: {\n",
      "        manual_step_learning_rate {\n",
      "          initial_learning_rate: 0.0001\n",
      "          schedule {\n",
      "            step: 50000\n",
      "            learning_rate: 0.00009\n",
      "          }\n",
      "          schedule {\n",
      "            step: 100000\n",
      "            learning_rate: 0.000081\n",
      "          }\n",
      "          schedule {\n",
      "            step: 150000\n",
      "            learning_rate: 0.0000729\n",
      "          }\n",
      "          schedule {\n",
      "            step: 200000\n",
      "            learning_rate: 0.00006561\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      momentum_optimizer_value: 0.9\n",
      "    }\n",
      "    use_moving_average: false\n",
      "  }\n",
      "  gradient_clipping_by_norm: 10.0\n",
      "  fine_tune_checkpoint: \"/content/drive/My Drive/model_frcnn_inception_resnet_v2_final/model.ckpt\"\n",
      "  from_detection_checkpoint: true\n",
      "  # Note: The below line limits the training process to 200K steps, which we\n",
      "  # empirically found to be sufficient enough to train the pets dataset. This\n",
      "  # effectively bypasses the learning rate schedule (the learning rate will\n",
      "  # never decay). Remove the below line to train indefinitely.\n",
      "  num_steps: 250000\n",
      "  data_augmentation_options {\n",
      "    random_horizontal_flip {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "train_input_reader: {\n",
      "  tf_record_input_reader {\n",
      "    input_path: \"/content/drive/My Drive/xmls/trainxml.record\"\n",
      "  }\n",
      "  label_map_path: \"/content/drive/My Drive/label_map.pbtxt\"\n",
      "}\n",
      "\n",
      "eval_config: {\n",
      "  num_examples: 2004\n",
      "  # Note: The below line limits the evaluation process to 10 evaluations.\n",
      "  # Remove the below line to evaluate indefinitely.\n",
      "  max_evals: 2004\n",
      "}\n",
      "\n",
      "eval_input_reader: {\n",
      "  tf_record_input_reader {\n",
      "    input_path: \"/content/drive/My Drive/xmls/valxml.record\"\n",
      "  }\n",
      "  label_map_path: \"/content/drive/My Drive/label_map.pbtxt\"\n",
      "  shuffle: false\n",
      "  num_readers: 1\n",
      "}"
     ]
    }
   ],
   "source": [
    "#check pipeline.config correct\n",
    "#!cat /content/drive/'My Drive'/model_frcnn_inception_resnet_v2_final/pipeline.config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# write pipeline.config if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "JE7lFfLc1JJg",
    "outputId": "175a5fa8-4881-4676-8ffb-f618fa80b7a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing pipeline.config\n"
     ]
    }
   ],
   "source": [
    "%%writefile pipeline.config\n",
    "\n",
    "\n",
    "model {\n",
    "  faster_rcnn {\n",
    "    num_classes: 3\n",
    "    image_resizer {\n",
    "      keep_aspect_ratio_resizer {\n",
    "        min_dimension: 600\n",
    "        max_dimension: 1024\n",
    "      }\n",
    "    }\n",
    "    feature_extractor {\n",
    "      type: 'faster_rcnn_inception_resnet_v2'\n",
    "      first_stage_features_stride: 8\n",
    "    }\n",
    "    first_stage_anchor_generator {\n",
    "      grid_anchor_generator {\n",
    "        scales: [0.25, 0.5, 1.0, 2.0]\n",
    "        aspect_ratios: [0.5, 1.0, 2.0]\n",
    "        height_stride: 8\n",
    "        width_stride: 8\n",
    "      }\n",
    "    }\n",
    "    first_stage_atrous_rate: 2\n",
    "    first_stage_box_predictor_conv_hyperparams {\n",
    "      op: CONV\n",
    "      regularizer {\n",
    "        l2_regularizer {\n",
    "          weight: 0.0\n",
    "        }\n",
    "      }\n",
    "      initializer {\n",
    "        truncated_normal_initializer {\n",
    "          stddev: 0.01\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "    first_stage_nms_score_threshold: 0.0\n",
    "    first_stage_nms_iou_threshold: 0.7\n",
    "    first_stage_max_proposals: 300\n",
    "    first_stage_localization_loss_weight: 2.0\n",
    "    first_stage_objectness_loss_weight: 1.0\n",
    "    initial_crop_size: 17\n",
    "    maxpool_kernel_size: 1\n",
    "    maxpool_stride: 1\n",
    "    second_stage_box_predictor {\n",
    "      mask_rcnn_box_predictor {\n",
    "        use_dropout: false\n",
    "        dropout_keep_probability: 1.0\n",
    "        fc_hyperparams {\n",
    "          op: FC\n",
    "          regularizer {\n",
    "            l2_regularizer {\n",
    "              weight: 0.0\n",
    "            }\n",
    "          }\n",
    "          initializer {\n",
    "            variance_scaling_initializer {\n",
    "              factor: 1.0\n",
    "              uniform: true\n",
    "              mode: FAN_AVG\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "    second_stage_post_processing {\n",
    "      batch_non_max_suppression {\n",
    "        score_threshold: 0.0\n",
    "        iou_threshold: 0.6\n",
    "        max_detections_per_class: 100\n",
    "        max_total_detections: 300\n",
    "      }\n",
    "      score_converter: SOFTMAX\n",
    "    }\n",
    "    second_stage_localization_loss_weight: 2.0\n",
    "    second_stage_classification_loss_weight: 1.0\n",
    "  }\n",
    "}\n",
    "\n",
    "train_config: {\n",
    "  batch_size: 1\n",
    "  optimizer {\n",
    "    momentum_optimizer: {\n",
    "      learning_rate: {\n",
    "        manual_step_learning_rate {\n",
    "          initial_learning_rate: 0.0001\n",
    "          schedule {\n",
    "            step: 50000\n",
    "            learning_rate: 0.00009\n",
    "          }\n",
    "          schedule {\n",
    "            step: 100000\n",
    "            learning_rate: 0.000081\n",
    "          }\n",
    "          schedule {\n",
    "            step: 150000\n",
    "            learning_rate: 0.0000729\n",
    "          }\n",
    "          schedule {\n",
    "            step: 200000\n",
    "            learning_rate: 0.00006561\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "      momentum_optimizer_value: 0.9\n",
    "    }\n",
    "    use_moving_average: false\n",
    "  }\n",
    "  gradient_clipping_by_norm: 10.0\n",
    "  fine_tune_checkpoint: \"/content/drive/My Drive/model_frcnn_inception_resnet_v2_final/model.ckpt\"\n",
    "  from_detection_checkpoint: true\n",
    "  # Note: The below line limits the training process to 200K steps, which we\n",
    "  # empirically found to be sufficient enough to train the pets dataset. This\n",
    "  # effectively bypasses the learning rate schedule (the learning rate will\n",
    "  # never decay). Remove the below line to train indefinitely.\n",
    "  num_steps: 250000\n",
    "  data_augmentation_options {\n",
    "    random_horizontal_flip {\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "train_input_reader: {\n",
    "  tf_record_input_reader {\n",
    "    input_path: \"/content/drive/My Drive/xmls/trainxml.record\"\n",
    "  }\n",
    "  label_map_path: \"/content/drive/My Drive/label_map.pbtxt\"\n",
    "}\n",
    "\n",
    "eval_config: {\n",
    "  num_examples: 2004\n",
    "  # Note: The below line limits the evaluation process to 10 evaluations.\n",
    "  # Remove the below line to evaluate indefinitely.\n",
    "  max_evals: 2004\n",
    "}\n",
    "\n",
    "eval_input_reader: {\n",
    "  tf_record_input_reader {\n",
    "    input_path: \"/content/drive/My Drive/xmls/valxml.record\"\n",
    "  }\n",
    "  label_map_path: \"/content/drive/My Drive/label_map.pbtxt\"\n",
    "  shuffle: false\n",
    "  num_readers: 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "7725_PsT1PH3",
    "outputId": "51aff0d9-fea8-425c-9ea6-0e51e9dfd45c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/content/drive/My Drive/model_frcnn_inception_resnet_v2_final/pipeline.config'"
      ]
     },
     "execution_count": 41,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!rm /content/drive/'My Drive'/model_frcnn_inception_resnet_v2_final/pipeline.config\n",
    "shutil.move('pipeline.config', CONFIG_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "8d2QIpsF1mpr",
    "outputId": "7beece33-978b-45ba-cf3c-e88b874a2e78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Copyright 2017 The TensorFlow Authors. All Rights Reserved.\n",
      "#\n",
      "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
      "# you may not use this file except in compliance with the License.\n",
      "# You may obtain a copy of the License at\n",
      "#\n",
      "#     http://www.apache.org/licenses/LICENSE-2.0\n",
      "#\n",
      "# Unless required by applicable law or agreed to in writing, software\n",
      "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
      "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
      "# See the License for the specific language governing permissions and\n",
      "# limitations under the License.\n",
      "# ==============================================================================\n",
      "\"\"\"Binary to run train and evaluation on object detection model.\"\"\"\n",
      "\n",
      "from __future__ import absolute_import\n",
      "from __future__ import division\n",
      "from __future__ import print_function\n",
      "\n",
      "from absl import flags\n",
      "\n",
      "import tensorflow as tf\n",
      "\n",
      "from object_detection import model_hparams\n",
      "from object_detection import model_lib\n",
      "\n",
      "flags.DEFINE_string(\n",
      "    'model_dir', None, 'Path to output model directory '\n",
      "    'where event and checkpoint files will be written.')\n",
      "flags.DEFINE_string('pipeline_config_path', None, 'Path to pipeline config '\n",
      "                    'file.')\n",
      "flags.DEFINE_integer('num_train_steps', None, 'Number of train steps.')\n",
      "flags.DEFINE_boolean('eval_training_data', False,\n",
      "                     'If training data should be evaluated for this job. Note '\n",
      "                     'that one call only use this in eval-only mode, and '\n",
      "                     '`checkpoint_dir` must be supplied.')\n",
      "flags.DEFINE_integer('sample_1_of_n_eval_examples', 1, 'Will sample one of '\n",
      "                     'every n eval input examples, where n is provided.')\n",
      "flags.DEFINE_integer('sample_1_of_n_eval_on_train_examples', 5, 'Will sample '\n",
      "                     'one of every n train input examples for evaluation, '\n",
      "                     'where n is provided. This is only used if '\n",
      "                     '`eval_training_data` is True.')\n",
      "flags.DEFINE_string(\n",
      "    'hparams_overrides', None, 'Hyperparameter overrides, '\n",
      "    'represented as a string containing comma-separated '\n",
      "    'hparam_name=value pairs.')\n",
      "flags.DEFINE_string(\n",
      "    'checkpoint_dir', None, 'Path to directory holding a checkpoint.  If '\n",
      "    '`checkpoint_dir` is provided, this binary operates in eval-only mode, '\n",
      "    'writing resulting metrics to `model_dir`.')\n",
      "flags.DEFINE_boolean(\n",
      "    'run_once', False, 'If running in eval-only mode, whether to run just '\n",
      "    'one round of eval vs running continuously (default).'\n",
      ")\n",
      "FLAGS = flags.FLAGS\n",
      "\n",
      "\n",
      "def main(unused_argv):\n",
      "  flags.mark_flag_as_required('model_dir')\n",
      "  flags.mark_flag_as_required('pipeline_config_path')\n",
      "  config = tf.estimator.RunConfig(model_dir=FLAGS.model_dir, save_checkpoints_steps=12500, keep_checkpoint_max=200)\n",
      "\n",
      "  train_and_eval_dict = model_lib.create_estimator_and_inputs(\n",
      "      run_config=config,\n",
      "      hparams=model_hparams.create_hparams(FLAGS.hparams_overrides),\n",
      "      pipeline_config_path=FLAGS.pipeline_config_path,\n",
      "      train_steps=FLAGS.num_train_steps,\n",
      "      sample_1_of_n_eval_examples=FLAGS.sample_1_of_n_eval_examples,\n",
      "      sample_1_of_n_eval_on_train_examples=(\n",
      "          FLAGS.sample_1_of_n_eval_on_train_examples))\n",
      "  estimator = train_and_eval_dict['estimator']\n",
      "  train_input_fn = train_and_eval_dict['train_input_fn']\n",
      "  eval_input_fns = train_and_eval_dict['eval_input_fns']\n",
      "  eval_on_train_input_fn = train_and_eval_dict['eval_on_train_input_fn']\n",
      "  predict_input_fn = train_and_eval_dict['predict_input_fn']\n",
      "  train_steps = train_and_eval_dict['train_steps']\n",
      "\n",
      "  if FLAGS.checkpoint_dir:\n",
      "    if FLAGS.eval_training_data:\n",
      "      name = 'training_data'\n",
      "      input_fn = eval_on_train_input_fn\n",
      "    else:\n",
      "      name = 'validation_data'\n",
      "      # The first eval input will be evaluated.\n",
      "      input_fn = eval_input_fns[0]\n",
      "    if FLAGS.run_once:\n",
      "      estimator.evaluate(input_fn,\n",
      "                         steps=None,\n",
      "                         checkpoint_path=tf.train.latest_checkpoint(\n",
      "                             FLAGS.checkpoint_dir))\n",
      "    else:\n",
      "      model_lib.continuous_eval(estimator, FLAGS.checkpoint_dir, input_fn,\n",
      "                                train_steps, name)\n",
      "  else:\n",
      "    train_spec, eval_specs = model_lib.create_train_and_eval_specs(\n",
      "        train_input_fn,\n",
      "        eval_input_fns,\n",
      "        eval_on_train_input_fn,\n",
      "        predict_input_fn,\n",
      "        train_steps,\n",
      "        eval_on_train_data=False)\n",
      "\n",
      "    # Currently only a single Eval Spec is allowed.\n",
      "    tf.estimator.train_and_evaluate(estimator, train_spec, eval_specs[0])\n",
      "\n",
      "\n",
      "if __name__ == '__main__':\n",
      "  tf.app.run()"
     ]
    }
   ],
   "source": [
    "#check model_main.py is correct\n",
    "#!cat /content/models/research/object_detection/model_main.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# write model_main.py if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "m_hasxYw1rkb",
    "outputId": "461139f5-3758-49eb-852d-42dd6deffacf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /content/models/research/object_detection/model_main.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /content/models/research/object_detection/model_main.py\n",
    "\n",
    "# Copyright 2017 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\"\"\"Binary to run train and evaluation on object detection model.\"\"\"\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from absl import flags\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from object_detection import model_hparams\n",
    "from object_detection import model_lib\n",
    "\n",
    "flags.DEFINE_string(\n",
    "    'model_dir', None, 'Path to output model directory '\n",
    "    'where event and checkpoint files will be written.')\n",
    "flags.DEFINE_string('pipeline_config_path', None, 'Path to pipeline config '\n",
    "                    'file.')\n",
    "flags.DEFINE_integer('num_train_steps', None, 'Number of train steps.')\n",
    "flags.DEFINE_boolean('eval_training_data', False,\n",
    "                     'If training data should be evaluated for this job. Note '\n",
    "                     'that one call only use this in eval-only mode, and '\n",
    "                     '`checkpoint_dir` must be supplied.')\n",
    "flags.DEFINE_integer('sample_1_of_n_eval_examples', 1, 'Will sample one of '\n",
    "                     'every n eval input examples, where n is provided.')\n",
    "flags.DEFINE_integer('sample_1_of_n_eval_on_train_examples', 5, 'Will sample '\n",
    "                     'one of every n train input examples for evaluation, '\n",
    "                     'where n is provided. This is only used if '\n",
    "                     '`eval_training_data` is True.')\n",
    "flags.DEFINE_string(\n",
    "    'hparams_overrides', None, 'Hyperparameter overrides, '\n",
    "    'represented as a string containing comma-separated '\n",
    "    'hparam_name=value pairs.')\n",
    "flags.DEFINE_string(\n",
    "    'checkpoint_dir', None, 'Path to directory holding a checkpoint.  If '\n",
    "    '`checkpoint_dir` is provided, this binary operates in eval-only mode, '\n",
    "    'writing resulting metrics to `model_dir`.')\n",
    "flags.DEFINE_boolean(\n",
    "    'run_once', False, 'If running in eval-only mode, whether to run just '\n",
    "    'one round of eval vs running continuously (default).'\n",
    ")\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "\n",
    "def main(unused_argv):\n",
    "  flags.mark_flag_as_required('model_dir')\n",
    "  flags.mark_flag_as_required('pipeline_config_path')\n",
    "  config = tf.estimator.RunConfig(model_dir=FLAGS.model_dir, save_checkpoints_steps=12500, keep_checkpoint_max=200)\n",
    "\n",
    "  train_and_eval_dict = model_lib.create_estimator_and_inputs(\n",
    "      run_config=config,\n",
    "      hparams=model_hparams.create_hparams(FLAGS.hparams_overrides),\n",
    "      pipeline_config_path=FLAGS.pipeline_config_path,\n",
    "      train_steps=FLAGS.num_train_steps,\n",
    "      sample_1_of_n_eval_examples=FLAGS.sample_1_of_n_eval_examples,\n",
    "      sample_1_of_n_eval_on_train_examples=(\n",
    "          FLAGS.sample_1_of_n_eval_on_train_examples))\n",
    "  estimator = train_and_eval_dict['estimator']\n",
    "  train_input_fn = train_and_eval_dict['train_input_fn']\n",
    "  eval_input_fns = train_and_eval_dict['eval_input_fns']\n",
    "  eval_on_train_input_fn = train_and_eval_dict['eval_on_train_input_fn']\n",
    "  predict_input_fn = train_and_eval_dict['predict_input_fn']\n",
    "  train_steps = train_and_eval_dict['train_steps']\n",
    "\n",
    "  if FLAGS.checkpoint_dir:\n",
    "    if FLAGS.eval_training_data:\n",
    "      name = 'training_data'\n",
    "      input_fn = eval_on_train_input_fn\n",
    "    else:\n",
    "      name = 'validation_data'\n",
    "      # The first eval input will be evaluated.\n",
    "      input_fn = eval_input_fns[0]\n",
    "    if FLAGS.run_once:\n",
    "      estimator.evaluate(input_fn,\n",
    "                         steps=None,\n",
    "                         checkpoint_path=tf.train.latest_checkpoint(\n",
    "                             FLAGS.checkpoint_dir))\n",
    "    else:\n",
    "      model_lib.continuous_eval(estimator, FLAGS.checkpoint_dir, input_fn,\n",
    "                                train_steps, name)\n",
    "  else:\n",
    "    train_spec, eval_specs = model_lib.create_train_and_eval_specs(\n",
    "        train_input_fn,\n",
    "        eval_input_fns,\n",
    "        eval_on_train_input_fn,\n",
    "        predict_input_fn,\n",
    "        train_steps,\n",
    "        eval_on_train_data=False)\n",
    "\n",
    "    # Currently only a single Eval Spec is allowed.\n",
    "    tf.estimator.train_and_evaluate(estimator, train_spec, eval_specs[0])\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  tf.app.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run to start training\n",
    "\n",
    "ensure pipeline_config_path and model_dir are correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "NQQ3mgQI1vSP",
    "outputId": "7ccd62af-98b8-421b-eab1-77fcb1fc0db8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /content/models/research/object_detection/model_main.py:110: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
      "\n",
      "WARNING:tensorflow:From /content/models/research/object_detection/utils/config_util.py:102: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "W0414 09:39:57.920130 140296329365376 module_wrapper.py:139] From /content/models/research/object_detection/utils/config_util.py:102: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "WARNING:tensorflow:From /content/models/research/object_detection/model_lib.py:628: The name tf.logging.warning is deprecated. Please use tf.compat.v1.logging.warning instead.\n",
      "\n",
      "W0414 09:39:57.923847 140296329365376 module_wrapper.py:139] From /content/models/research/object_detection/model_lib.py:628: The name tf.logging.warning is deprecated. Please use tf.compat.v1.logging.warning instead.\n",
      "\n",
      "WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n",
      "W0414 09:39:57.924021 140296329365376 model_lib.py:629] Forced number of epochs for all eval validations to be 1.\n",
      "WARNING:tensorflow:From /content/models/research/object_detection/utils/config_util.py:488: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n",
      "W0414 09:39:57.924160 140296329365376 module_wrapper.py:139] From /content/models/research/object_detection/utils/config_util.py:488: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n",
      "INFO:tensorflow:Maybe overwriting train_steps: None\n",
      "I0414 09:39:57.924242 140296329365376 config_util.py:488] Maybe overwriting train_steps: None\n",
      "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
      "I0414 09:39:57.924333 140296329365376 config_util.py:488] Maybe overwriting use_bfloat16: False\n",
      "INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: 1\n",
      "I0414 09:39:57.924405 140296329365376 config_util.py:488] Maybe overwriting sample_1_of_n_eval_examples: 1\n",
      "INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n",
      "I0414 09:39:57.924478 140296329365376 config_util.py:488] Maybe overwriting eval_num_epochs: 1\n",
      "INFO:tensorflow:Maybe overwriting load_pretrained: True\n",
      "I0414 09:39:57.924545 140296329365376 config_util.py:488] Maybe overwriting load_pretrained: True\n",
      "INFO:tensorflow:Ignoring config override key: load_pretrained\n",
      "I0414 09:39:57.924629 140296329365376 config_util.py:498] Ignoring config override key: load_pretrained\n",
      "WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
      "W0414 09:39:57.925226 140296329365376 model_lib.py:645] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
      "INFO:tensorflow:create_estimator_and_inputs: use_tpu False, export_to_tpu False\n",
      "I0414 09:39:57.925323 140296329365376 model_lib.py:680] create_estimator_and_inputs: use_tpu False, export_to_tpu False\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/content/drive/My Drive/model_frcnn_inception_resnet_v2_final/training/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 12500, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 200, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f98e0b26828>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "I0414 09:39:57.925688 140296329365376 estimator.py:212] Using config: {'_model_dir': '/content/drive/My Drive/model_frcnn_inception_resnet_v2_final/training/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 12500, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 200, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f98e0b26828>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "WARNING:tensorflow:Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f98e0b8a6a8>) includes params argument, but params are not passed to Estimator.\n",
      "W0414 09:39:57.925875 140296329365376 model_fn.py:630] Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f98e0b8a6a8>) includes params argument, but params are not passed to Estimator.\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "I0414 09:39:57.926643 140296329365376 estimator_training.py:186] Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "I0414 09:39:57.926825 140296329365376 training.py:612] Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 12500 or save_checkpoints_secs None.\n",
      "I0414 09:39:57.927055 140296329365376 training.py:700] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 12500 or save_checkpoints_secs None.\n",
      "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "W0414 09:39:57.959658 140296329365376 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "WARNING:tensorflow:From /content/models/research/object_detection/data_decoders/tf_example_decoder.py:182: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
      "\n",
      "W0414 09:39:57.970183 140296329365376 module_wrapper.py:139] From /content/models/research/object_detection/data_decoders/tf_example_decoder.py:182: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
      "\n",
      "WARNING:tensorflow:From /content/models/research/object_detection/data_decoders/tf_example_decoder.py:197: The name tf.VarLenFeature is deprecated. Please use tf.io.VarLenFeature instead.\n",
      "\n",
      "W0414 09:39:57.970369 140296329365376 module_wrapper.py:139] From /content/models/research/object_detection/data_decoders/tf_example_decoder.py:197: The name tf.VarLenFeature is deprecated. Please use tf.io.VarLenFeature instead.\n",
      "\n",
      "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:64: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
      "\n",
      "W0414 09:39:57.985228 140296329365376 module_wrapper.py:139] From /content/models/research/object_detection/builders/dataset_builder.py:64: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
      "\n",
      "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
      "W0414 09:39:57.986737 140296329365376 dataset_builder.py:72] num_readers has been reduced to 1 to match input file shards.\n",
      "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:86: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.experimental.parallel_interleave(...)`.\n",
      "W0414 09:39:57.991530 140296329365376 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:86: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.experimental.parallel_interleave(...)`.\n",
      "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
      "W0414 09:39:57.991695 140296329365376 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
      "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:155: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "W0414 09:39:58.011454 140296329365376 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:155: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "WARNING:tensorflow:Entity <function build.<locals>.process_fn at 0x7f98e0b8aa60> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "W0414 09:39:58.027831 140296329365376 ag_logging.py:146] Entity <function build.<locals>.process_fn at 0x7f98e0b8aa60> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From /content/models/research/object_detection/utils/ops.py:491: The name tf.is_nan is deprecated. Please use tf.math.is_nan instead.\n",
      "\n",
      "W0414 09:39:58.179685 140296329365376 module_wrapper.py:139] From /content/models/research/object_detection/utils/ops.py:491: The name tf.is_nan is deprecated. Please use tf.math.is_nan instead.\n",
      "\n",
      "WARNING:tensorflow:From /content/models/research/object_detection/utils/ops.py:493: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0414 09:39:58.183166 140296329365376 deprecation.py:323] From /content/models/research/object_detection/utils/ops.py:493: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /content/models/research/object_detection/core/preprocessor.py:627: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0414 09:39:58.224545 140296329365376 module_wrapper.py:139] From /content/models/research/object_detection/core/preprocessor.py:627: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /content/models/research/object_detection/core/preprocessor.py:2689: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
      "\n",
      "W0414 09:39:58.269443 140296329365376 module_wrapper.py:139] From /content/models/research/object_detection/core/preprocessor.py:2689: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
      "\n",
      "WARNING:tensorflow:From /content/models/research/object_detection/inputs.py:168: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W0414 09:39:58.304569 140296329365376 deprecation.py:323] From /content/models/research/object_detection/inputs.py:168: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From /content/models/research/object_detection/inputs.py:470: The name tf.string_to_hash_bucket_fast is deprecated. Please use tf.strings.to_hash_bucket_fast instead.\n",
      "\n",
      "W0414 09:39:58.578218 140296329365376 module_wrapper.py:139] From /content/models/research/object_detection/inputs.py:470: The name tf.string_to_hash_bucket_fast is deprecated. Please use tf.strings.to_hash_bucket_fast instead.\n",
      "\n",
      "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:158: batch_and_drop_remainder (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.batch(..., drop_remainder=True)`.\n",
      "W0414 09:39:58.597811 140296329365376 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:158: batch_and_drop_remainder (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.batch(..., drop_remainder=True)`.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "I0414 09:39:58.613736 140296329365376 estimator.py:1148] Calling model_fn.\n",
      "WARNING:tensorflow:From /content/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:168: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "W0414 09:39:58.637737 140296329365376 module_wrapper.py:139] From /content/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:168: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "I0414 09:39:58.638070 140296329365376 regularizers.py:98] Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "I0414 09:39:58.638323 140296329365376 regularizers.py:98] Scale of 0 disables regularizer.\n",
      "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "W0414 09:39:58.639225 140296329365376 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From /content/models/research/object_detection/core/anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n",
      "\n",
      "W0414 09:40:06.822613 140296329365376 module_wrapper.py:139] From /content/models/research/object_detection/core/anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n",
      "\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "I0414 09:40:06.959375 140296329365376 regularizers.py:98] Scale of 0 disables regularizer.\n",
      "WARNING:tensorflow:From /content/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:558: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
      "\n",
      "W0414 09:40:06.959795 140296329365376 module_wrapper.py:139] From /content/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:558: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
      "\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "I0414 09:40:07.016235 140296329365376 regularizers.py:98] Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0414 09:40:07.016583 140296329365376 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
      "WARNING:tensorflow:From /content/models/research/object_detection/box_coders/faster_rcnn_box_coder.py:82: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0414 09:40:07.635580 140296329365376 module_wrapper.py:139] From /content/models/research/object_detection/box_coders/faster_rcnn_box_coder.py:82: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /content/models/research/object_detection/core/minibatch_sampler.py:85: The name tf.random_shuffle is deprecated. Please use tf.random.shuffle instead.\n",
      "\n",
      "W0414 09:40:07.675611 140296329365376 module_wrapper.py:139] From /content/models/research/object_detection/core/minibatch_sampler.py:85: The name tf.random_shuffle is deprecated. Please use tf.random.shuffle instead.\n",
      "\n",
      "WARNING:tensorflow:From /content/models/research/object_detection/utils/spatial_transform_ops.py:419: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "box_ind is deprecated, use box_indices instead\n",
      "W0414 09:40:07.891668 140296329365376 deprecation.py:506] From /content/models/research/object_detection/utils/spatial_transform_ops.py:419: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "box_ind is deprecated, use box_indices instead\n",
      "WARNING:tensorflow:From /content/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:191: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
      "\n",
      "W0414 09:40:07.906173 140296329365376 module_wrapper.py:139] From /content/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:191: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
      "\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "I0414 09:40:07.906517 140296329365376 regularizers.py:98] Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "I0414 09:40:07.906633 140296329365376 regularizers.py:98] Scale of 0 disables regularizer.\n",
      "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/layers/python/layers/layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "W0414 09:40:09.171215 140296329365376 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/layers/python/layers/layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "I0414 09:40:09.173720 140296329365376 regularizers.py:98] Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "I0414 09:40:09.190679 140296329365376 regularizers.py:98] Scale of 0 disables regularizer.\n",
      "WARNING:tensorflow:From /content/models/research/object_detection/utils/variables_helper.py:179: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "W0414 09:40:09.215714 140296329365376 module_wrapper.py:139] From /content/models/research/object_detection/utils/variables_helper.py:179: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /content/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:2768: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.train.get_or_create_global_step\n",
      "W0414 09:40:09.215910 140296329365376 deprecation.py:323] From /content/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:2768: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.train.get_or_create_global_step\n",
      "WARNING:tensorflow:From /content/models/research/object_detection/utils/variables_helper.py:139: The name tf.train.NewCheckpointReader is deprecated. Please use tf.compat.v1.train.NewCheckpointReader instead.\n",
      "\n",
      "W0414 09:40:09.220492 140296329365376 module_wrapper.py:139] From /content/models/research/object_detection/utils/variables_helper.py:139: The name tf.train.NewCheckpointReader is deprecated. Please use tf.compat.v1.train.NewCheckpointReader instead.\n",
      "\n",
      "WARNING:tensorflow:From /content/models/research/object_detection/utils/variables_helper.py:142: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "W0414 09:40:09.224988 140296329365376 module_wrapper.py:139] From /content/models/research/object_detection/utils/variables_helper.py:142: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:From /content/models/research/object_detection/model_lib.py:353: The name tf.train.init_from_checkpoint is deprecated. Please use tf.compat.v1.train.init_from_checkpoint instead.\n",
      "\n",
      "W0414 09:40:09.231321 140296329365376 module_wrapper.py:139] From /content/models/research/object_detection/model_lib.py:353: The name tf.train.init_from_checkpoint is deprecated. Please use tf.compat.v1.train.init_from_checkpoint instead.\n",
      "\n",
      "WARNING:tensorflow:From /content/models/research/object_detection/core/losses.py:177: The name tf.losses.huber_loss is deprecated. Please use tf.compat.v1.losses.huber_loss instead.\n",
      "\n",
      "W0414 09:40:11.896468 140296329365376 module_wrapper.py:139] From /content/models/research/object_detection/core/losses.py:177: The name tf.losses.huber_loss is deprecated. Please use tf.compat.v1.losses.huber_loss instead.\n",
      "\n",
      "WARNING:tensorflow:From /content/models/research/object_detection/core/losses.py:183: The name tf.losses.Reduction is deprecated. Please use tf.compat.v1.losses.Reduction instead.\n",
      "\n",
      "W0414 09:40:11.897623 140296329365376 module_wrapper.py:139] From /content/models/research/object_detection/core/losses.py:183: The name tf.losses.Reduction is deprecated. Please use tf.compat.v1.losses.Reduction instead.\n",
      "\n",
      "WARNING:tensorflow:From /content/models/research/object_detection/core/losses.py:350: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "W0414 09:40:11.938718 140296329365376 deprecation.py:323] From /content/models/research/object_detection/core/losses.py:350: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "WARNING:tensorflow:From /content/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:2710: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "W0414 09:40:12.151210 140296329365376 module_wrapper.py:139] From /content/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:2710: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From /content/models/research/object_detection/model_lib.py:380: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
      "\n",
      "W0414 09:40:12.152046 140296329365376 module_wrapper.py:139] From /content/models/research/object_detection/model_lib.py:380: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
      "\n",
      "WARNING:tensorflow:From /content/models/research/object_detection/builders/optimizer_builder.py:58: The name tf.train.MomentumOptimizer is deprecated. Please use tf.compat.v1.train.MomentumOptimizer instead.\n",
      "\n",
      "W0414 09:40:12.158638 140296329365376 module_wrapper.py:139] From /content/models/research/object_detection/builders/optimizer_builder.py:58: The name tf.train.MomentumOptimizer is deprecated. Please use tf.compat.v1.train.MomentumOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /content/models/research/object_detection/model_lib.py:398: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n",
      "W0414 09:40:12.158843 140296329365376 module_wrapper.py:139] From /content/models/research/object_detection/model_lib.py:398: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /content/models/research/object_detection/model_lib.py:408: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "W0414 09:40:12.159039 140296329365376 module_wrapper.py:139] From /content/models/research/object_detection/model_lib.py:408: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "WARNING:tensorflow:From /content/models/research/object_detection/model_lib.py:515: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "W0414 09:40:20.072834 140296329365376 module_wrapper.py:139] From /content/models/research/object_detection/model_lib.py:515: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "WARNING:tensorflow:From /content/models/research/object_detection/model_lib.py:519: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
      "\n",
      "W0414 09:40:21.042769 140296329365376 module_wrapper.py:139] From /content/models/research/object_detection/model_lib.py:519: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From /content/models/research/object_detection/model_lib.py:520: The name tf.train.Scaffold is deprecated. Please use tf.compat.v1.train.Scaffold instead.\n",
      "\n",
      "W0414 09:40:21.043076 140296329365376 module_wrapper.py:139] From /content/models/research/object_detection/model_lib.py:520: The name tf.train.Scaffold is deprecated. Please use tf.compat.v1.train.Scaffold instead.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "I0414 09:40:21.043457 140296329365376 estimator.py:1150] Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "I0414 09:40:21.044685 140296329365376 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "I0414 09:40:26.386580 140296329365376 monitored_session.py:240] Graph was finalized.\n",
      "2020-04-14 09:40:26.386953: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX512F\n",
      "2020-04-14 09:40:26.391292: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000140000 Hz\n",
      "2020-04-14 09:40:26.391472: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x198b480 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-04-14 09:40:26.391497: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2020-04-14 09:40:26.395697: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2020-04-14 09:40:26.508533: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-04-14 09:40:26.509032: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x198b2c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2020-04-14 09:40:26.509064: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P4, Compute Capability 6.1\n",
      "2020-04-14 09:40:26.509267: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-04-14 09:40:26.509613: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
      "name: Tesla P4 major: 6 minor: 1 memoryClockRate(GHz): 1.1135\n",
      "pciBusID: 0000:00:04.0\n",
      "2020-04-14 09:40:26.509941: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2020-04-14 09:40:26.511501: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2020-04-14 09:40:26.513408: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2020-04-14 09:40:26.513744: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2020-04-14 09:40:26.515371: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2020-04-14 09:40:26.516291: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2020-04-14 09:40:26.519755: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2020-04-14 09:40:26.519877: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-04-14 09:40:26.520309: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-04-14 09:40:26.520627: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
      "2020-04-14 09:40:26.520687: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2020-04-14 09:40:26.521802: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-04-14 09:40:26.521828: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
      "2020-04-14 09:40:26.521838: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
      "2020-04-14 09:40:26.521944: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-04-14 09:40:26.522390: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-04-14 09:40:26.522717: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2020-04-14 09:40:26.522758: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7123 MB memory) -> physical GPU (device: 0, name: Tesla P4, pci bus id: 0000:00:04.0, compute capability: 6.1)\n",
      "INFO:tensorflow:Restoring parameters from /content/drive/My Drive/model_frcnn_inception_resnet_v2_final/training/model.ckpt-62500\n",
      "I0414 09:40:26.527063 140296329365376 saver.py:1284] Restoring parameters from /content/drive/My Drive/model_frcnn_inception_resnet_v2_final/training/model.ckpt-62500\n",
      "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/saver.py:1069: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file utilities to get mtimes.\n",
      "W0414 09:40:30.492625 140296329365376 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/saver.py:1069: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file utilities to get mtimes.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "I0414 09:40:32.226897 140296329365376 session_manager.py:500] Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "I0414 09:40:32.707463 140296329365376 session_manager.py:502] Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 62500 into /content/drive/My Drive/model_frcnn_inception_resnet_v2_final/training/model.ckpt.\n",
      "I0414 09:40:46.921891 140296329365376 basic_session_run_hooks.py:606] Saving checkpoints for 62500 into /content/drive/My Drive/model_frcnn_inception_resnet_v2_final/training/model.ckpt.\n",
      "2020-04-14 09:41:06.113623: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2020-04-14 09:41:06.666538: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2020-04-14 09:41:09.179207: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.13GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2020-04-14 09:41:09.233581: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.07GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2020-04-14 09:41:09.273697: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.06GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "INFO:tensorflow:loss = 0.14597675, step = 62500\n",
      "I0414 09:41:12.424801 140296329365376 basic_session_run_hooks.py:262] loss = 0.14597675, step = 62500\n",
      "INFO:tensorflow:global_step/sec: 0.805711\n",
      "I0414 09:43:16.538100 140296329365376 basic_session_run_hooks.py:692] global_step/sec: 0.805711\n",
      "INFO:tensorflow:loss = 0.22542498, step = 62600 (124.115 sec)\n",
      "I0414 09:43:16.539784 140296329365376 basic_session_run_hooks.py:260] loss = 0.22542498, step = 62600 (124.115 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.88847\n",
      "I0414 09:45:09.091058 140296329365376 basic_session_run_hooks.py:692] global_step/sec: 0.88847\n",
      "INFO:tensorflow:loss = 0.31186217, step = 62700 (112.552 sec)\n",
      "I0414 09:45:09.092041 140296329365376 basic_session_run_hooks.py:260] loss = 0.31186217, step = 62700 (112.552 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.888555\n",
      "I0414 09:47:01.633405 140296329365376 basic_session_run_hooks.py:692] global_step/sec: 0.888555\n",
      "INFO:tensorflow:loss = 0.5992482, step = 62800 (112.543 sec)\n",
      "I0414 09:47:01.634936 140296329365376 basic_session_run_hooks.py:260] loss = 0.5992482, step = 62800 (112.543 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.888944\n",
      "I0414 09:48:54.126381 140296329365376 basic_session_run_hooks.py:692] global_step/sec: 0.888944\n",
      "INFO:tensorflow:loss = 0.17922835, step = 62900 (112.493 sec)\n",
      "I0414 09:48:54.127654 140296329365376 basic_session_run_hooks.py:260] loss = 0.17922835, step = 62900 (112.493 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.888496\n",
      "I0414 09:50:46.676254 140296329365376 basic_session_run_hooks.py:692] global_step/sec: 0.888496\n",
      "INFO:tensorflow:loss = 0.044222683, step = 63000 (112.550 sec)\n",
      "I0414 09:50:46.678089 140296329365376 basic_session_run_hooks.py:260] loss = 0.044222683, step = 63000 (112.550 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.888643\n",
      "I0414 09:52:39.207321 140296329365376 basic_session_run_hooks.py:692] global_step/sec: 0.888643\n",
      "INFO:tensorflow:loss = 0.21404205, step = 63100 (112.530 sec)\n",
      "I0414 09:52:39.208317 140296329365376 basic_session_run_hooks.py:260] loss = 0.21404205, step = 63100 (112.530 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.888135\n",
      "I0414 09:54:31.802860 140296329365376 basic_session_run_hooks.py:692] global_step/sec: 0.888135\n",
      "INFO:tensorflow:loss = 0.15241167, step = 63200 (112.597 sec)\n",
      "I0414 09:54:31.805102 140296329365376 basic_session_run_hooks.py:260] loss = 0.15241167, step = 63200 (112.597 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.886831\n",
      "I0414 09:56:24.563865 140296329365376 basic_session_run_hooks.py:692] global_step/sec: 0.886831\n",
      "INFO:tensorflow:loss = 1.180803, step = 63300 (112.760 sec)\n",
      "I0414 09:56:24.565050 140296329365376 basic_session_run_hooks.py:260] loss = 1.180803, step = 63300 (112.760 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.887364\n",
      "I0414 09:58:17.257143 140296329365376 basic_session_run_hooks.py:692] global_step/sec: 0.887364\n",
      "INFO:tensorflow:loss = 0.13385332, step = 63400 (112.694 sec)\n",
      "I0414 09:58:17.258993 140296329365376 basic_session_run_hooks.py:260] loss = 0.13385332, step = 63400 (112.694 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.885494\n",
      "I0414 10:00:10.188451 140296329365376 basic_session_run_hooks.py:692] global_step/sec: 0.885494\n",
      "INFO:tensorflow:loss = 0.1381893, step = 63500 (112.931 sec)\n",
      "I0414 10:00:10.189677 140296329365376 basic_session_run_hooks.py:260] loss = 0.1381893, step = 63500 (112.931 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.885778\n",
      "I0414 10:02:03.083427 140296329365376 basic_session_run_hooks.py:692] global_step/sec: 0.885778\n",
      "INFO:tensorflow:loss = 0.14136896, step = 63600 (112.896 sec)\n",
      "I0414 10:02:03.086146 140296329365376 basic_session_run_hooks.py:260] loss = 0.14136896, step = 63600 (112.896 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.884597\n",
      "I0414 10:03:56.129297 140296329365376 basic_session_run_hooks.py:692] global_step/sec: 0.884597\n",
      "INFO:tensorflow:loss = 0.08115591, step = 63700 (113.044 sec)\n",
      "I0414 10:03:56.130477 140296329365376 basic_session_run_hooks.py:260] loss = 0.08115591, step = 63700 (113.044 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.885598\n",
      "I0414 10:05:49.047277 140296329365376 basic_session_run_hooks.py:692] global_step/sec: 0.885598\n",
      "INFO:tensorflow:loss = 0.24578217, step = 63800 (112.918 sec)\n",
      "I0414 10:05:49.048648 140296329365376 basic_session_run_hooks.py:260] loss = 0.24578217, step = 63800 (112.918 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.884029\n",
      "I0414 10:07:42.165807 140296329365376 basic_session_run_hooks.py:692] global_step/sec: 0.884029\n",
      "INFO:tensorflow:loss = 0.36833647, step = 63900 (113.118 sec)\n",
      "I0414 10:07:42.167034 140296329365376 basic_session_run_hooks.py:260] loss = 0.36833647, step = 63900 (113.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.884891\n",
      "I0414 10:09:35.174102 140296329365376 basic_session_run_hooks.py:692] global_step/sec: 0.884891\n",
      "INFO:tensorflow:loss = 0.1700592, step = 64000 (113.009 sec)\n",
      "I0414 10:09:35.175711 140296329365376 basic_session_run_hooks.py:260] loss = 0.1700592, step = 64000 (113.009 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.884205\n",
      "I0414 10:11:28.269935 140296329365376 basic_session_run_hooks.py:692] global_step/sec: 0.884205\n",
      "INFO:tensorflow:loss = 0.20645437, step = 64100 (113.095 sec)\n",
      "I0414 10:11:28.271191 140296329365376 basic_session_run_hooks.py:260] loss = 0.20645437, step = 64100 (113.095 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.883581\n",
      "I0414 10:13:21.445793 140296329365376 basic_session_run_hooks.py:692] global_step/sec: 0.883581\n",
      "INFO:tensorflow:loss = 1.5936007, step = 64200 (113.176 sec)\n",
      "I0414 10:13:21.447411 140296329365376 basic_session_run_hooks.py:260] loss = 1.5936007, step = 64200 (113.176 sec)\n"
     ]
    }
   ],
   "source": [
    "!python3 /content/models/research/object_detection/model_main.py \\\n",
    "    --pipeline_config_path=/content/drive/My\\ Drive/model_frcnn_inception_resnet_v2_final/pipeline.config \\\n",
    "    --model_dir=/content/drive/My\\ Drive/model_frcnn_inception_resnet_v2_final/training/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pFjvcG4_tQIy"
   },
   "outputs": [],
   "source": [
    "#use this for renaming if necessary\n",
    "#!mv /content/drive/'My Drive'/model_frcnn_inception_resnet_v2_final/'model (1).ckpt.index' /content/drive/'My Drive'/model_frcnn_inception_resnet_v2_final/model.ckpt.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_wllcVpzUV8U"
   },
   "outputs": [],
   "source": [
    "#additional code for rpn2 and more can be found in frozen_graph.ipynb and actual_inference.ipynb\n",
    "#not provided here for simplicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zlmFqvggt6_C"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Untitled0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
